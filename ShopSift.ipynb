{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOezY9hjXgoQ5wWIa/d0gJq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subbu-chowdary/ShopSift/blob/main/ShopSift.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqs0UJpiZxZC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install numpy pandas faker plotly scikit-learn tqdm\n",
        "\n",
        "# Now you can run your script\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "import random\n",
        "import plotly.express as px\n",
        "from itertools import combinations\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "np.random.seed(32)\n",
        "random.seed(32)\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "def generate_data(num_products=10, num_customers=100, num_transactions=500):\n",
        "    products = [fake.word() for _ in range(num_products)]\n",
        "    transactions = []\n",
        "    for _ in range(num_transactions):\n",
        "        customer_id = random.randint(1, num_customers)\n",
        "        basket_size = random.randint(1, 5)\n",
        "        basket = random.sample(products, basket_size)\n",
        "        transactions.append({\n",
        "            'customer_id': customer_id,\n",
        "            'products': basket\n",
        "        })\n",
        "    df = pd.DataFrame(transactions)\n",
        "    df_encoded = df.explode('products').pivot_table(\n",
        "        index='customer_id',\n",
        "        columns='products',\n",
        "        aggfunc=lambda x: 1,\n",
        "        fill_value=0\n",
        "    )\n",
        "    return df_encoded\n",
        "\n",
        "def simple_apriori(df, min_support=0.1, min_confidence=0.5):\n",
        "    def support(item_set):\n",
        "        return (df[list(item_set)].sum(axis=1) == len(item_set)).mean()\n",
        "\n",
        "    items = set(df.columns)\n",
        "    item_sets = [frozenset([item]) for item in items]\n",
        "    rules = []\n",
        "\n",
        "    for k in range(2, len(items) + 1):\n",
        "        item_sets = [s for s in combinations(items, k) if support(s) >= min_support]\n",
        "\n",
        "        for item_set in item_sets:\n",
        "            item_set = frozenset(item_set)\n",
        "            for i in range(1, len(item_set)):\n",
        "                for antecedent in combinations(item_set, i):\n",
        "                    antecedent = frozenset(antecedent)\n",
        "                    consequent = item_set - antecedent\n",
        "                    confidence = support(item_set) / support(antecedent)\n",
        "                    if confidence >= min_confidence:\n",
        "                        lift = confidence / support(consequent)\n",
        "                        rules.append({\n",
        "                            'antecedent': ','.join(antecedent),\n",
        "                            'consequent': ','.join(consequent),\n",
        "                            'support': support(item_set),\n",
        "                            'confidence': confidence,\n",
        "                            'lift': lift\n",
        "                        })\n",
        "                        if len(rules) >= 10:\n",
        "                            break\n",
        "        if len(rules) >= 10:\n",
        "            break\n",
        "\n",
        "    return pd.DataFrame(rules).sort_values('lift', ascending=False)\n",
        "\n",
        "def perform_kmeans_with_progress(df, n_clusters=3, update_interval=5):\n",
        "    scaler = StandardScaler()\n",
        "    df_scaled = scaler.fit_transform(df)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=32, max_iter=100)\n",
        "\n",
        "    with tqdm(total=kmeans.max_iter, desc=\"k-means Clustering\") as pbar:\n",
        "        for i in range(kmeans.max_iter):\n",
        "            kmeans.fit(df_scaled)\n",
        "            pbar.update(1)\n",
        "\n",
        "            if i % update_interval == 0:\n",
        "                yield kmeans.labels_\n",
        "            if kmeans.n_iter_ <= i + 1:\n",
        "                break\n",
        "\n",
        "    return kmeans.labels_\n",
        "\n",
        "def visualize_apriori_rules(rules, top_n=10):\n",
        "    top_rules = rules.head(top_n)\n",
        "    fig = px.scatter_3d(\n",
        "        top_rules, x=\"support\", y=\"confidence\", z=\"lift\",\n",
        "        color=\"lift\", size=\"support\",\n",
        "        hover_name=\"antecedent\", hover_data={\"consequent\": True},\n",
        "        labels={\"support\": \"Support\", \"confidence\": \"Confidence\", \"lift\": \"Lift\"},\n",
        "        title=f\"Top {top_n} Association Rules\"\n",
        "    )\n",
        "    print(\"Generating Apriori HTML visualization...\")\n",
        "    fig.write_html(\"apriori3d.html\")\n",
        "    print(\"Apriori rules visualization saved as 'apriori3d.html'.\")\n",
        "    return fig\n",
        "\n",
        "def visualize_kmeans_clusters(df, cluster_labels):\n",
        "    pca = PCA(n_components=3)\n",
        "    pca_result = pca.fit_transform(df)\n",
        "    fig = px.scatter_3d(\n",
        "        x=pca_result[:, 0], y=pca_result[:, 1], z=pca_result[:, 2],\n",
        "        color=cluster_labels,\n",
        "        title=\"Customer Cluster Visualization\"\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def main():\n",
        "    print(\"Gathering synthetic data....\")\n",
        "    df_encoded = generate_data(num_products=10, num_customers=100, num_transactions=500)\n",
        "    print(f\"Dataset shape: {df_encoded.shape}\")\n",
        "\n",
        "    print(\"Performing Apriori algorithm...\")\n",
        "    rules = simple_apriori(df_encoded, min_support=0.1, min_confidence=0.5)\n",
        "\n",
        "    if not rules.empty:\n",
        "        print(f\"Apriori algorithm complete, found {len(rules)} rules\")\n",
        "        visualize_apriori_rules(rules)\n",
        "    else:\n",
        "        print(\"No rules found with the given support and confidence levels.\")\n",
        "\n",
        "    print(\"Performing k-means clustering...\")\n",
        "    kmeans_generator = perform_kmeans_with_progress(df_encoded, n_clusters=3, update_interval=5)\n",
        "\n",
        "    for i, labels in enumerate(kmeans_generator):\n",
        "        print(f\"k-means iteration {i * 5}\")\n",
        "        viz = visualize_kmeans_clusters(df_encoded, labels)\n",
        "        html_filename = f\"customer_clusters_3d_step_{i}.html\"\n",
        "        viz.write_html(html_filename)\n",
        "        print(f\"Intermediate visualization saved as '{html_filename}'\")\n",
        "\n",
        "    final_labels = labels\n",
        "    print(\"k-means clustering completed.\")\n",
        "    final_viz = visualize_kmeans_clusters(df_encoded, final_labels)\n",
        "    final_viz.write_html(\"customer_cluster_3d_final.html\")\n",
        "    print(\"Final customer cluster visualization saved as 'customer_cluster_3d_final.html'.\")\n",
        "    print(\"Analysis completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr7p_wTmaFO_",
        "outputId": "47247299-16ba-4ee0-f4ed-76c0970ae72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting faker\n",
            "  Downloading Faker-28.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading Faker-28.1.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-28.1.0\n",
            "Gathering synthetic data....\n",
            "Dataset shape: (99, 10)\n",
            "Performing Apriori algorithm...\n",
            "Apriori algorithm complete, found 50 rules\n",
            "Generating Apriori HTML visualization...\n",
            "Apriori rules visualization saved as 'apriori3d.html'.\n",
            "Performing k-means clustering...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "k-means Clustering:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "k-means Clustering:   1%|          | 1/100 [00:00<00:15,  6.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-means iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "k-means Clustering:   2%|▏         | 2/100 [00:00<00:21,  4.60it/s]/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "k-means Clustering:   5%|▌         | 5/100 [00:00<00:09, 10.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intermediate visualization saved as 'customer_clusters_3d_step_0.html'\n",
            "k-means clustering completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final customer cluster visualization saved as 'customer_cluster_3d_final.html'.\n",
            "Analysis completed.\n"
          ]
        }
      ]
    }
  ]
}